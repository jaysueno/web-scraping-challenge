{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the relevant libraries you may use\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Mars Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASA  Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be scraping information from the NASA website regarding Mars\n",
    "# Define the the URL\n",
    "url = 'https://mars.nasa.gov/news/'\n",
    "\n",
    "# Retrive the page with the requests module\n",
    "response = requests.get(url)\n",
    "# Convert the response to text to obtain the html\n",
    "html = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish chrome driver executable path. Make sure to define actual location on your drive.\n",
    "executable_path ={'executable_path': 'C:/Users/jaysu/chromedriver.exe'}\n",
    "# Open a splinter browser\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the defined URL on your splinter broswers\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BeautifulSoup object with the splinter broswer.html object and parse the html with 'html.parser' or 'lxml'\n",
    "soup = bs(browser.html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the first instance of latest news title text and assign to a variable\n",
    "# Find the first article\n",
    "first_news_article = soup.find('li', class_=\"slide\")\n",
    "# Find the title within that article summary and convert into .text or .get_text() and then .strip() of '/n'\n",
    "news_title = first_news_article.find('div', class_='content_title').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Follow NASA's Perseverance Rover in Real Time on Its Way to Mars\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the first instance of latest paragraph text and assign to a variable\n",
    "# Find the paragraph within that article summary and convert into .text and then .strip() of '/n'\n",
    "news_p = first_news_article.find('div', class_=\"article_teaser_body\").text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A crisply rendered web application can show you where the agency's Mars 2020 mission is right now as it makes its way to the Red Planet for a Feb. 18, 2021, landing.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaysu\\anaconda3\\lib\\site-packages\\splinter\\driver\\webdriver\\__init__.py:525: FutureWarning: browser.find_link_by_partial_text is deprecated. Use browser.links.find_by_partial_text instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Open a splinter browser to scrape the desired images\n",
    "# Define the URL path\n",
    "url_2 = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "\n",
    "# Using the already established splinter engine, open the url in broswer\n",
    "# Visit the defined URL on your splinter broswers\n",
    "browser.visit(url_2)\n",
    "\n",
    "# delay action until browser loads\n",
    "time.sleep(2)\n",
    "\n",
    "# click on the sprinter browser link 'FULL IMAGE' to see the image we want to store\n",
    "browser.click_link_by_partial_text('FULL IMAGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA16613_ip.jpg\n"
     ]
    }
   ],
   "source": [
    "# Scrape the web page for the image URL\n",
    "# First save the root webpage URL to add to the image source ('img src')\n",
    "jpl_url = 'https://www.jpl.nasa.gov'\n",
    "\n",
    "# Soupify the browser html\n",
    "soup = bs(browser.html, 'html.parser')\n",
    "\n",
    "# Locate the 'div' and class attribute where the image is found and \n",
    "image_soup = soup.find('div', class_='fancybox-inner')\n",
    "\n",
    "# Isolate the image url image source string by .find() and calling the ['src']\n",
    "image_url_string = image_soup.find('img')['src']\n",
    "\n",
    "# Assign the string compound image url to a variable\n",
    "featured_image_url = jpl_url + image_url_string\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribute</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Equatorial Diameter:</th>\n",
       "      <td>6,792 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polar Diameter:</th>\n",
       "      <td>6,752 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mass:</th>\n",
       "      <td>6.39 × 10^23 kg (0.11 Earths)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moons:</th>\n",
       "      <td>2 (Phobos &amp; Deimos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbit Distance:</th>\n",
       "      <td>227,943,824 km (1.38 AU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbit Period:</th>\n",
       "      <td>687 days (1.9 years)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surface Temperature:</th>\n",
       "      <td>-87 to -5 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Record:</th>\n",
       "      <td>2nd millennium BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recorded By:</th>\n",
       "      <td>Egyptian astronomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Value\n",
       "Attribute                                          \n",
       "Equatorial Diameter:                       6,792 km\n",
       "Polar Diameter:                            6,752 km\n",
       "Mass:                 6.39 × 10^23 kg (0.11 Earths)\n",
       "Moons:                          2 (Phobos & Deimos)\n",
       "Orbit Distance:            227,943,824 km (1.38 AU)\n",
       "Orbit Period:                  687 days (1.9 years)\n",
       "Surface Temperature:                   -87 to -5 °C\n",
       "First Record:                     2nd millennium BC\n",
       "Recorded By:                   Egyptian astronomers"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use Pandas to scrape the table information from the space-fact.com website on Mars\n",
    "# Define the url\n",
    "url = 'https://space-facts.com/mars/'\n",
    "\n",
    "# Using pd.read_html() will pull a list dataframes of all the tables\n",
    "tables = pd.read_html(url)\n",
    "\n",
    "# We want to slice off the 1st table from the list\n",
    "mars_facts_tbl = tables[0]\n",
    "\n",
    "# Name the columns\n",
    "mars_facts_tbl.columns = ['Attribute', 'Value']\n",
    "\n",
    "mars_facts_tbl.set_index('Attribute', inplace=True)\n",
    "mars_facts_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>Value</th>\\n    </tr>\\n    <tr>\\n      <th>Attribute</th>\\n      <th></th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>Equatorial Diameter:</th>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <th>Polar Diameter:</th>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <th>Mass:</th>\\n      <td>6.39 × 10^23 kg (0.11 Earths)</td>\\n    </tr>\\n    <tr>\\n      <th>Moons:</th>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <th>Orbit Distance:</th>\\n      <td>227,943,824 km (1.38 AU)</td>\\n    </tr>\\n    <tr>\\n      <th>Orbit Period:</th>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <th>Surface Temperature:</th>\\n      <td>-87 to -5 °C</td>\\n    </tr>\\n    <tr>\\n      <th>First Record:</th>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <th>Recorded By:</th>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the pandas dataframe table into html using .to_html()\n",
    "html_mars_tbl = mars_facts_tbl.to_html()\n",
    "html_mars_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the USGS Astrogeology site to obtain high resolution images for each of Mar's hemispheres.\n",
    "# Define URL\n",
    "url_3 = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "root_usgs_url = 'https://astrogeology.usgs.gov/'\n",
    "\n",
    "# Use splinter browser to open url site\n",
    "browser.visit(url_3)\n",
    "\n",
    "#soupify\n",
    "soup = bs(browser.html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrape of Cerberus Hemisphere Enhanced successful\n",
      "Scrape of Schiaparelli Hemisphere Enhanced successful\n",
      "Scrape of Syrtis Major Hemisphere Enhanced successful\n",
      "Scrape of Valles Marineris Hemisphere Enhanced successful\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store dictonary values for the keys of 'image_url' and 'title'\n",
    "hemisphere_image_list = []\n",
    "\n",
    "# Use .find_all() to slice out the html we will loop through to visit different webpages and scrape the data\n",
    "image_links = soup.find_all('div', class_='item')\n",
    "\n",
    "# Start the for loop\n",
    "for item in image_links:\n",
    "    \n",
    "    # Find the url link string from the 'a' tag and call the 'href' string\n",
    "    link = item.find('a')['href']\n",
    "    \n",
    "    # Combine the root url from above and the link url\n",
    "    url_4 = root_usgs_url + link\n",
    "    \n",
    "    # Open the splinter browser using the url_4 link we just created\n",
    "    browser.visit(url_4)\n",
    "    \n",
    "    # Let the browser load for 1 seconds before scraping data\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Soupify the page\n",
    "    soup = bs(browser.html, 'html.parser')\n",
    "    \n",
    "    # Find the link to the image in the 'ul' tag, then the 'a' tag, and then call the 2nd item 'href'\n",
    "    # Store link string in variable 'image_link_hemi'\n",
    "    image_link_hemi = soup.find('ul').find_all('a')[1]['href']\n",
    "    \n",
    "    # Find the title name using the 'h2' tag and class attribute 'title', and then pull the .text\n",
    "    # Store title in variable 'title_text'\n",
    "    title_text = soup.find('h2', class_='title').text\n",
    "    \n",
    "    # Append the hemisphere list with a dictionary of the keys and values\n",
    "    hemisphere_image_list.append({\n",
    "        'title': title_text, \n",
    "        'img_url': image_link_hemi\n",
    "    })\n",
    "    \n",
    "    # Print out success message\n",
    "    print(f'Scrape of {title_text} successful')\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cerberus Hemisphere Enhanced',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif'},\n",
       " {'title': 'Schiaparelli Hemisphere Enhanced',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif'},\n",
       " {'title': 'Syrtis Major Hemisphere Enhanced',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif'},\n",
       " {'title': 'Valles Marineris Hemisphere Enhanced',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif'}]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if data is all there\n",
    "hemisphere_image_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
